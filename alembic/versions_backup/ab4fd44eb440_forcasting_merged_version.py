"""forcasting merged version

Revision ID: ab4fd44eb440
Revises: 9115ce03c384
Create Date: 2025-12-11 18:38:18.195886

"""

from typing import Sequence, Union

import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

from alembic import op

# revision identifiers, used by Alembic.
revision: str = "ab4fd44eb440"
down_revision: Union[str, Sequence[str], None] = "9115ce03c384"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "prediction_results",
        sa.Column("analysis_id", sa.Integer(), nullable=False),
        sa.Column("time", sa.DateTime(), nullable=False),
        sa.Column("value", sa.Float(), nullable=False),
        sa.ForeignKeyConstraint(
            ["analysis_id"],
            ["timeseries.analyses.id"],
        ),
        sa.PrimaryKeyConstraint("analysis_id", "time"),
        schema="timeseries",
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "datapoints",
        sa.Column("dataset_id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column("time", postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
        sa.Column("value", sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
        sa.ForeignKeyConstraint(["dataset_id"], ["datasets.id"], name=op.f("datapoints_dataset_id_fkey")),
        sa.PrimaryKeyConstraint("dataset_id", "time", name=op.f("datapoints_pkey")),
    )
    op.create_table(
        "datasets",
        sa.Column(
            "id",
            sa.INTEGER(),
            server_default=sa.text("nextval('datasets_id_seq'::regclass)"),
            autoincrement=True,
            nullable=False,
        ),
        sa.Column("name", sa.VARCHAR(length=255), autoincrement=False, nullable=False),
        sa.Column("start_date", postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
        sa.Column("description", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.PrimaryKeyConstraint("id", name="datasets_pkey"),
        postgresql_ignore_search_path=False,
    )
    op.create_index(op.f("ix_datasets_name"), "datasets", ["name"], unique=True)
    op.create_table(
        "analyses",
        sa.Column(
            "id",
            sa.INTEGER(),
            server_default=sa.text("nextval('analyses_id_seq'::regclass)"),
            autoincrement=True,
            nullable=False,
        ),
        sa.Column("dataset_id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column("model", sa.VARCHAR(length=255), autoincrement=False, nullable=False),
        sa.Column("name", sa.VARCHAR(length=255), autoincrement=False, nullable=False),
        sa.Column("description", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.ForeignKeyConstraint(["dataset_id"], ["datasets.id"], name="analyses_dataset_id_fkey"),
        sa.PrimaryKeyConstraint("id", name="analyses_pkey"),
        postgresql_ignore_search_path=False,
    )
    op.create_index(op.f("ix_analyses_dataset_id"), "analyses", ["dataset_id"], unique=False)
    op.create_table(
        "prediction_results",
        sa.Column("analysis_id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column("time", postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
        sa.Column("value", sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
        sa.ForeignKeyConstraint(["analysis_id"], ["analyses.id"], name=op.f("prediction_results_analysis_id_fkey")),
        sa.PrimaryKeyConstraint("analysis_id", "time", name=op.f("prediction_results_pkey")),
    )
    op.create_table(
        "alembic_version",
        sa.Column("version_num", sa.VARCHAR(length=32), autoincrement=False, nullable=False),
        sa.PrimaryKeyConstraint("version_num", name=op.f("alembic_version_pkc")),
    )
    op.create_table(
        "anomalies",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column("analysis_id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column("start", postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
        sa.Column("end", postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
        sa.Column(
            "type", postgresql.ENUM("point", "contextual", name="anomalytype"), autoincrement=False, nullable=False
        ),
        sa.Column("validated", sa.BOOLEAN(), autoincrement=False, nullable=False),
        sa.ForeignKeyConstraint(["analysis_id"], ["analyses.id"], name=op.f("anomalies_analysis_id_fkey")),
        sa.PrimaryKeyConstraint("id", name=op.f("anomalies_pkey")),
    )
    op.create_index(op.f("ix_anomalies_analysis_id"), "anomalies", ["analysis_id"], unique=False)
    op.drop_table("prediction_results", schema="timeseries")
    # ### end Alembic commands ###
